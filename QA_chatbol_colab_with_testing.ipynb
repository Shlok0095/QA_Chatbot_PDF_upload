{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers sentence-transformers faiss-cpu torch cohere"
      ],
      "metadata": {
        "id": "ftJn8wXCo9YB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "import pandas as pd\n",
        "import cohere  # Add Cohere for text generation\n",
        "import os"
      ],
      "metadata": {
        "id": "V-0TG6_roZTz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Cohere client (replace with your API key)\n",
        "cohere_api_key = \"USe_ypur_own_key_to_cross_check_coz_it's_restricted\"  # Add your Cohere API key here\n",
        "co_client = cohere.Client(cohere_api_key)"
      ],
      "metadata": {
        "id": "s6VrzrZkoZWM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset (replace with your own dataset or use a sample one)\n",
        "data = [\n",
        "    \"The company's revenue grew by 15% in the last quarter.\",\n",
        "    \"Customer satisfaction scores improved from 85% to 92%.\",\n",
        "    \"The new product launch increased market share by 5%.\",\n",
        "    \"Employee turnover rate decreased from 12% to 8% annually.\",\n",
        "    \"The company expanded operations to three new countries in Europe.\"\n",
        "]\n",
        "df = pd.DataFrame(data, columns=['text'])\n",
        "\n"
      ],
      "metadata": {
        "id": "qMeeCPP8oZYk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the embedding model\n",
        "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n"
      ],
      "metadata": {
        "id": "dl8xIZlXoZaV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create FAISS index\n",
        "dimension = embed_model.get_sentence_embedding_dimension()\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n"
      ],
      "metadata": {
        "id": "PxOqIJKooZc1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to embed and add data to FAISS\n",
        "def embed_and_add(texts):\n",
        "    embeddings = embed_model.encode(texts)\n",
        "    index.add(np.array(embeddings).astype('float32'))\n",
        "    return embeddings\n",
        "\n"
      ],
      "metadata": {
        "id": "-FhraJCvoZge"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed and add the dataset\n",
        "embeddings = embed_and_add(df['text'].tolist())\n",
        "\n",
        "print(\"Data embedded and added to FAISS index.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgyKX35poZi9",
        "outputId": "a772fa9b-e616-434d-a546-06ab6402534a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data embedded and added to FAISS index.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the models and FAISS index\n",
        "output_dir = 'rag_qa_model'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "TTaBHPntoZle"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save embedding model\n",
        "embed_model.save(f'{output_dir}/embed_model')\n",
        "\n"
      ],
      "metadata": {
        "id": "Sj9QiAkqoZn9"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save FAISS index\n",
        "faiss.write_index(index, f'{output_dir}/faiss_index.bin')\n",
        "\n"
      ],
      "metadata": {
        "id": "LoGTuM-boZqP"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the dataframe\n",
        "df.to_csv(f'{output_dir}/data.csv', index=False)\n",
        "\n",
        "print(f\"Embedding model and FAISS index saved to {output_dir}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFLMmvl9oZsc",
        "outputId": "7457827e-bf15-4036-c5cc-908775afe73e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding model and FAISS index saved to rag_qa_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_qa(query, top_k=3):\n",
        "    # Embed the query\n",
        "    query_embedding = embed_model.encode([query])[0]\n",
        "\n",
        "    # Retrieve relevant documents from FAISS\n",
        "    _, I = index.search(np.array([query_embedding]).astype('float32'), top_k)\n",
        "\n",
        "    # Prepare context\n",
        "    context = \"\\n\\n\".join([df['text'].iloc[i] for i in I[0]])\n",
        "\n",
        "    # Construct the input prompt\n",
        "    input_text = f\"Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
        "\n",
        "    # Use Cohere to generate an answer\n",
        "    response = co_client.generate(\n",
        "        model='command-xlarge-nightly',  # Use an accessible model\n",
        "        prompt=input_text,\n",
        "        max_tokens=150,\n",
        "        temperature=0.7,\n",
        "        k=0,\n",
        "        stop_sequences=[\"\\n\"]\n",
        "    )\n",
        "\n",
        "    # Extract the generated answer\n",
        "    answer = response.generations[0].text.strip()\n",
        "\n",
        "    return answer\n"
      ],
      "metadata": {
        "id": "JE8wyoEpoZu7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example queries to test the model\n",
        "queries = [\n",
        "    \"How did the company's revenue change recently?\",\n",
        "    \"What happened to customer satisfaction?\",\n",
        "    \"Did the company expand its operations?\",\n",
        "    \"How did the new product launch affect the company?\",\n",
        "    \"What changed in terms of employee turnover?\"\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "kn7FK69ZoZxl"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run example queries and print results\n",
        "print(\"Testing the RAG QA model with example queries:\\n\")\n",
        "for query in queries:\n",
        "    print(f\"Query: {query}\")\n",
        "    answer = rag_qa(query)\n",
        "    print(f\"Answer: {answer}\\n\")\n",
        "\n",
        "print(\"RAG QA model test complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tfp9bDTYo5d3",
        "outputId": "d1561b89-22d9-49cd-a043-a0591391eaa8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the RAG QA model with example queries:\n",
            "\n",
            "Query: How did the company's revenue change recently?\n",
            "Answer: The company's revenue increased by 15% in the last quarter, indicating a positive financial growth trend. This growth could be attributed to various factors such as successful sales strategies, increased demand for their products or services, or effective marketing campaigns. The 15% revenue growth is a significant achievement and suggests that the company is expanding and performing well in the market.\n",
            "\n",
            "Query: What happened to customer satisfaction?\n",
            "Answer: Customer satisfaction scores improved from 85% to 92%.\n",
            "\n",
            "Query: Did the company expand its operations?\n",
            "Answer: Yes, the company expanded its operations to three new countries in Europe.\n",
            "\n",
            "Query: How did the new product launch affect the company?\n",
            "Answer: The new product launch had a positive impact on the company, contributing to a 5% increase in market share. This success, along with the expansion into three new European countries, likely played a significant role in the company's 15% revenue growth in the last quarter. The launch of new products can drive market share growth, attract new customers, and increase overall sales, which ultimately leads to higher revenue.\n",
            "\n",
            "Query: What changed in terms of employee turnover?\n",
            "Answer: The employee turnover rate decreased by 4% annually, from 12% to 8%.\n",
            "\n",
            "RAG QA model test complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T-vlOXa7pXi3"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YbcCdl1VsVwv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
